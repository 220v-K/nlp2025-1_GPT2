# Hyperparameters
accelerator: auto
batch_size: 96
devices: 1
epochs: 20
lr: 2e-05
margin: 2.0
max_length: 128
model_size: gpt2
num_workers: 48
output_dir: ../outputs_contrastive
para_dev: ../data/quora-dev.csv
para_test: ../data/quora-test-student.csv
para_train: ../data/quora-train.csv
pooling_method: last
precision: 16-mixed
seed: 11711

# Metrics per epoch
epoch	train_loss	train_acc	val_loss	val_acc	val_f1
0	N/A	N/A	300.8053	0.6562	0.0294
0	N/A	N/A	0.6419	0.5489	0.6170
1	1.3906	0.5315	0.5154	0.6223	0.6587
2	0.5630	0.5878	0.4531	0.6082	0.6516
3	0.5087	0.6454	0.4081	0.6968	0.7059
4	0.4056	0.6925	0.3974	0.6669	0.6866
5	0.3215	0.7370	0.3884	0.7218	0.7221
6	0.2445	0.7767	0.4051	0.7547	0.7442
7	0.2052	0.8145	0.4028	0.7615	0.7488
8	0.1349	0.8448	0.4144	0.7697	0.7547
9	0.1098	0.8614	0.4104	0.7602	0.7472
10	0.0927	0.8705	0.4046	0.7445	0.7359
11	0.0778	0.8819	0.4012	0.7487	0.7391
12	0.0657	0.8913	0.4040	0.7503	0.7401
13	0.0563	0.9006	0.4039	0.7564	0.7446
14	0.0488	0.9072	0.3980	0.7237	0.7213
15	0.0437	0.9116	0.4016	0.7554	0.7435
16	0.0390	0.9165	0.3962	0.7344	0.7289
17	0.0350	0.9212	0.3961	0.7341	0.7288
18	0.0319	0.9251	0.3942	0.7273	0.7240
19	0.0292	0.9285	0.3921	0.7354	0.7296
